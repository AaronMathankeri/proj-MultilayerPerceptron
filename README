//Copyright (C) 2017 Aaron Mathankeri (aaron@quantifiedag.com)
//License: QuantifiedAG Software License.  See LICENSE.txt for full license.

PROJECT NAME
Version:
---------------------
CONTENTS OF THIS FILE
---------------------
   
 * Introduction
 * Requirements
 * Installation
 * Configuration
 * Example
 * Troubleshooting
 * FAQ
 ---------------------
 INTRODUCTION
The multilayer perceptron(mlp), or feed forward neural network,
is a parametric pattern recognition model. It has acheived
much popularity in recent years due to the advances of many technologies
exploiting many core architectures.

Here, I implement a simple MLP using hyper efficient computational
subroutines to quickly train the network.

The MLP is fit to data sampled from U(-1,1) and evaluated for f(x) = x^2.
The goal of the MLP is to learn the x^2 given the dataset.
This framework is easily extended to different regression problems, and the
extension to classification requires the output be transformed using a
logistic sigmoid function.
 ---------------------
  REQUIREMENTS
 * Intel MKL installed locally.
 * Intel compiler supporting C++11
 * R >= 3.4.0
 ---------------------
 INSTALLATION
 Project can be cloned and run for a terminal.
 ---------------------
 CONFIGURATION
 Path to MKL must be set in 'Makefile'
 ---------------------
 EXAMPLE
 $ make
 $ [output]
 TRAINING NETWORK USING SGD...
 complete.
 For Input : -0.424845	 Target is 0.180493	 Output is  : 0.181313
 For Input : 0.57661	 Target is 0.332479	 Output is  : 0.336321
 ---------------------
 TROUBLESHOOTING
 Most errors will be setting the proper path to MKL
 Dynamically linking libraries will be an issure on OSX.
 Make sure to properly dynamically link in 'Makefile'
 ---------------------
 FAQ
 (1) What is the benefit of using this framework?
     For more information: //software.intel.com/en-us/mkl
 (2) What are the applications of Neural Networks?
     For more information: PRML by Christopher Bishop
 (3) Why not use more mainstream frameworks?
     It's faster. Much faster. This solution can be deployed
     on large compute clusters enabling rapid large-scale inference.
     Because of how light weight it is, it can be deployed on
     gateways and IoT devices where memory and compute architecture may
     be constrained.
 ---------------------